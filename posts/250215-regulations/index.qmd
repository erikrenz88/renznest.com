---
title: "Unconstitutionality"
date: "2025-02-15"
categories: [regulations, government, policy]
image: "image1.jpg" 
bluesky-comments:
    enabled: true
freeze: auto
execute:
  engine: python
  jupyter: true
---

```{python}
#| label: set up libraries, logging, and API key
import requests
import logging
import time
import pandas as pd
import gc 
import re
import urllib.parse
import csv
import concurrent
import gdown
import polars as pl
from bs4 import BeautifulSoup
import yaml
import nbformat
from dotenv import load_dotenv
import os
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from pathlib import Path
import pyarrow

# Detect if we're in GitHub Actions
#is_ci = os.environ.get("GITHUB_ACTIONS") == "true"

# Set the base directory accordingly
#if is_ci:
#    base_path = Path(os.environ["GITHUB_WORKSPACE"])
#    print("Running in GitHub Actions. Base path set to:", base_path)
#else:
#    base_path = Path(".").resolve()
#    print("Running locally. Base path set to:", base_path)

# download local .csv files
# Build paths to your data files
#rules_path = base_path / "posts" / "250215-regulations" / "federal_register_rule_counts.csv"
#doge_path = base_path / "posts" / "250215-regulations" / "regulation-data.csv"
#regs_path = Path('/home/runner/work/renznest.com/renznest.com/data.csv')

doge_url = 'https://media.githubusercontent.com/media/erikrenz88/renznest.com/refs/heads/main/posts/250215-regulations/regulation-data.csv'
rules_url = 'https://media.githubusercontent.com/media/erikrenz88/renznest.com/refs/heads/main/posts/250215-regulations/federal_register_rule_counts.csv'

# Check if the file already exists to avoid re-downloading
file_id = "1Re-xRy9d3jZmWOVjvC4uwyi8UChxzUIY"
output = "data.csv"

# Set up authentication from GitHub Secrets
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "credentials.json"

# local dev: load in full_regulations.csv
# regs = pl.read_csv('full_regulations.csv')

# Use gdown with credentials
gdown.download(id=file_id, output=output, quiet=False, fuzzy=True)

if not os.path.exists(output) or os.path.getsize(output) == 0:
    raise Exception("File download failed! Check Google Drive permissions and authentication.")

# Configure logging for progress tracking
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

load_dotenv()

# Define API key (replace with your actual API key)
API_KEY = os.getenv('GOV_API')
# Base URL for GovInfo API
GOVINFO_BASE_URL = "https://api.govinfo.gov"
```

```{python}
#| eval: false
#| label: python scripting to collect data from govinfo.gov
#def extract_offset_token(next_page_token):
#    #Extracts and properly decodes the offsetMark token for pagination.
#    if next_page_token.startswith("http"):  
#        parsed_url = urllib.parse.urlparse(next_page_token)
#        query_params = urllib.parse.parse_qs(parsed_url.query)
#        extracted_token = query_params.get("offsetMark", [""])[0]
#    else:
#        extracted_token = next_page_token  
#
#    return urllib.parse.unquote(extracted_token)

#def get_cfr_regulations(start_year=2012, end_year=2025, output_file="cfr_regulations.csv"):
    #Fetches all CFR regulations using pagination, streaming, and incremental file writing.
#    headers = {'Accept': 'application/json'}
    
    # Open file for streaming data storage
#    with open(output_file, "w", newline="", encoding="utf-8") as file:
#        writer = csv.writer(file)
#        writer.writerow(["packageId", "title", "dateIssued"])  # Header

#        for year in range(start_year, end_year + 1):
#            start_date = f"{year}-01-01T00:00:00Z"
#            end_date = f"{year}-12-31T23:59:59Z"
#            url = f"{GOVINFO_BASE_URL}/published/{start_date}/{end_date}"
#            params = {
#                "offsetMark": "*",
#                "pageSize": 100,
#                "collection": "CFR",
#                "api_key": API_KEY
#            }

#            logger.info(f"Fetching CFR regulations for {year}...")

#            while True:
#                try:
#                    response = requests.get(url, params=params, headers=headers, timeout=30, stream=True)
#                    response.raise_for_status()
#                    content = response.json()
#                    packages = content.get("packages", [])

#                    if not packages:
#                        logger.warning(f"No packages found for {year}.")
#                        break

#                    for pkg in packages:
#                        writer.writerow([pkg.get("packageId", ""), pkg.get("title", ""), pkg.get("dateIssued", "")])

                    # Pagination Handling
#                    if "nextPage" in content and content["nextPage"]:
#                        next_offset = extract_offset_token(content["nextPage"])
#                        if next_offset:
#                            params["offsetMark"] = next_offset
#                            time.sleep(1)
#                        else:
#                            logger.error("Failed to extract offsetMark. Stopping pagination.")
#                            break
#                    else:
#                        break  # No more pages

#                except requests.exceptions.RequestException as e:
#                    logger.error(f"API request failed for {year}: {e}")
#                    break  # Stop processing this year if there's an issue

#def get_cfr_agency(package_id):
    #Fetch agency information for a given CFR package from api.govinfo.gov.
#    url = f"{GOVINFO_BASE_URL}/packages/{package_id}/summary?api_key={API_KEY}"
#    headers = {'Accept': 'application/json'}
    
#    try:
#        response = requests.get(url, headers=headers, timeout=30)
#        response.raise_for_status()
#        data = response.json()
        
        # ✅ Agency information may be in 'organization' or 'agency' fields
#        agency = data.get("organization", data.get("agency", "Unknown Agency"))
#        return agency
#    except requests.exceptions.RequestException as e:
#        logger.error(f"Failed to retrieve agency for package {package_id}: {e}")
#        return "Unknown Agency"

#def get_granules(package_id):
    #Fetches granules (sections) for a given regulation package.
#    url = f"{GOVINFO_BASE_URL}/packages/{package_id}/granules?offsetMark=*&pageSize=100&api_key={API_KEY}"
#    try:
#        response = requests.get(url, headers={'Accept': 'application/json'}, timeout=30)
#        response.raise_for_status()
#        return response.json().get("granules", [])
#    except requests.exceptions.RequestException as e:
#        logger.error(f"Failed to retrieve granules for package {package_id}: {e}")
#        return []

#def get_package_text(package_id):
    #Fetches full text of a regulation in TXT format if available.
#    url = f"{GOVINFO_BASE_URL}/packages/{package_id}/summary?api_key={API_KEY}"
#    try:
#        response = requests.get(url, headers={'Accept': 'application/json'}, timeout=30)
#        response.raise_for_status()
#        summary = response.json()
        
#        if "download" in summary and "txtLink" in summary["download"]:
#            txt_url = summary["download"]["txtLink"] + f"?api_key={API_KEY}"
#            response = requests.get(txt_url, headers={'Accept': 'text/plain'}, timeout=30)
#            response.raise_for_status()
#            return response.text
#        else:
#            return "No text available"
#    except requests.exceptions.RequestException as e:
#        logger.error(f"Failed to retrieve text for package {package_id}: {e}")
#        return "No text available"

#def process_regulation_data(input_file="cfr_regulations.csv", output_file="full_regulations.csv"):
    #Processes CFR regulations: retrieves granules, full text, and agency info from api.govinfo.gov.
#    results = []
    
#    df = pd.read_csv(input_file)

#    def fetch_data(row):
        #Helper function for parallel execution.
#        package_id = row.packageId
#        text = get_package_text(package_id)
#        granules = get_granules(package_id)
        
        # ✅ Fetch Agency Name from GovInfo API
#        agency_name = get_cfr_agency(package_id)

#        return [package_id, row.title, row.dateIssued, agency_name, text, len(granules)]

#    logger.info(f"Processing {len(df)} CFR regulations with multi-threading...")

#    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
#        for result in executor.map(fetch_data, df.itertuples(index=False, name="CFRRecord")):
#            results.append(result)
#            gc.collect()

#    with open(output_file, "w", newline="", encoding="utf-8") as file:
#        writer = csv.writer(file)
#        writer.writerow(["packageId", "title", "dateIssued", "agency", "text", "granule_count"])
#        writer.writerows(results)

#    logger.info(f"Completed processing. Data saved to {output_file}")

# get_cfr_regulations(start_year=2012, end_year=2024)  # Fetches regulations and saves to CSV

# process_regulation_data()  # Retrieves granules & text, saves to a new CSV
```

```{python}
#| label: download data
rules = pl.read_csv(rules_url)
doge = pl.read_csv(doge_url)

#rules = pl.read_csv('posts/250215-regulations/federal_register_rule_counts.csv')
#doge = pl.read_csv('posts/250215-regulations/regulation-data.csv')
regs = pl.read_csv('data.csv')
```

```{python}
# Define bureaucratic and explanatory terms
# Bureaucratic & Explanatory Terms
bureaucratic_terms = ["shall", "must", "require", "submit", "authorize", "comply", "prohibit", "enforce", "mandatory"]
explanatory_terms = ["for the purposes of", "defined as", "background", "explains how"]

# Function to count occurrences of terms in text
def count_terms(text, terms):
    if text is None:
        return 0
    return sum(text.lower().count(term) for term in terms)

# Ensure dateIssued is properly converted to a date before extracting year
regs = regs.with_columns(pl.col("dateIssued").str.to_date("%Y-%m-%d").alias("dateIssued"))

# Transform Data
regs = (
    regs.with_columns([
        pl.col("dateIssued").dt.year().alias("year"),  # ✅ Extract year from actual date column
        pl.col("text").map_elements(lambda x: count_terms(x, bureaucratic_terms)).cast(pl.Int32).alias("bureaucratic_terms"),
        pl.col("text").map_elements(lambda x: count_terms(x, explanatory_terms)).cast(pl.Int32).alias("explanatory_terms"),
        pl.col("text").map_elements(lambda x: len(x.split()) if x else 0).cast(pl.Int32).alias("reg_word_count")  # Count words
    ])
    .with_columns([
        (pl.col("bureaucratic_terms") / (pl.col("explanatory_terms") + 1)).alias("complexity_ratio")  # Avoid division by zero
    ])
)
```

```{python}
# Group Data by Agency & Year
grouped_regs = (
    regs.group_by(["title", "year"])
    .agg(
        pl.sum("granule_count").alias("num_sections"),
        pl.sum("reg_word_count").alias("total_word_count"),
        pl.sum("bureaucratic_terms").alias("total_bureaucratic_terms"),
        pl.mean("complexity_ratio").alias("avg_complexity_ratio")
    )
)
```

```{python}
# Reshape Data: Melt DataFrame for Metric-Based Analysis
melted_regs = (
    grouped_regs.melt(
        id_vars=["title", "year"],
        value_vars=["total_word_count", "total_bureaucratic_terms", "avg_complexity_ratio"],
        variable_name="metric",
        value_name="value"
    )
)
```

```{python}
# Compute Year-over-Year Changes
def percent_change(new, old):
    return 0 if old == 0 else ((new - old) / old) * 100

years = sorted(grouped_regs["year"].unique().to_list())
analysis_results = []

for i in range(1, len(years)):
    prev_year = years[i - 1]
    curr_year = years[i]

    prev_data = melted_regs.filter(pl.col("year") == prev_year)
    curr_data = melted_regs.filter(pl.col("year") == curr_year)

    prev_word_count = prev_data.filter(pl.col("metric") == "total_word_count")["value"].sum()
    curr_word_count = curr_data.filter(pl.col("metric") == "total_word_count")["value"].sum()

    prev_bureaucratic = prev_data.filter(pl.col("metric") == "total_bureaucratic_terms")["value"].sum()
    curr_bureaucratic = curr_data.filter(pl.col("metric") == "total_bureaucratic_terms")["value"].sum()

    prev_complexity = prev_data.filter(pl.col("metric") == "avg_complexity_ratio")["value"].mean()
    curr_complexity = curr_data.filter(pl.col("metric") == "avg_complexity_ratio")["value"].mean()

    word_growth = percent_change(curr_word_count, prev_word_count)
    bureaucratic_change = percent_change(curr_bureaucratic, prev_bureaucratic)
    complexity_change = percent_change(curr_complexity, prev_complexity)

    efficiency_score = (bureaucratic_change + complexity_change) / (2 * word_growth) if word_growth != 0 else 0

    analysis_results.append({
        "year": curr_year,
        "word_growth": word_growth,
        "bureaucratic_change": bureaucratic_change,
        "complexity_change": complexity_change,
        "efficiency_score": efficiency_score
    })

# Convert results to DataFrame
df_results = pl.DataFrame(analysis_results)
```

```{python}
# Congress Law Mapping
congress_map = {
    "2012": [112], "2013": [113], "2014": [113],
    "2015": [114], "2016": [114],
    "2017": [115], "2018": [115],
    "2019": [116], "2020": [116],
    "2021": [117], "2022": [117],
    "2023": [118], "2024": [118]
}

laws_by_congress = {
    112: 284, 113: 296, 114: 329, 115: 442,
    116: 344, 117: 328, 118: 280
}

laws_by_year = {
    int(year): sum(laws_by_congress[congress] for congress in congress_map[year]) / 2
    for year in congress_map
}

laws_by_year_df = pl.DataFrame({"year": list(laws_by_year.keys()), "num_laws_passed": list(laws_by_year.values())})

# Compute Unconstitutionality Index
df_sect = (
    grouped_regs
    .join(laws_by_year_df, on="year", how="left")
    .join(rules, on="year", how="left")
    .with_columns(
        (pl.col("rule_count") / pl.col("num_laws_passed")).alias("unconstitutionality_index")
    )
    .join(doge, on="year", how="left")
    .rename({"word_count": "DOGE_word_count"})
    .melt(
        id_vars=["title", "year"],
        value_vars=[
            "total_bureaucratic_terms", "avg_complexity_ratio", "total_word_count",
            "rule_count", "num_laws_passed", "num_sections",
            "unconstitutionality_index", "DOGE_word_count", "regulation_count"
        ],
        variable_name="metric",
        value_name="value"
    )
    .with_columns(
        # Convert year to ISO-safe string for JavaScript
        pl.col("year").cast(pl.Int32).map_elements(lambda y: f"{y}-01-01").alias("year")
    )
)

# Reshape Data for Charts
charts = df_sect

# Laws and Rules Charts
lawrule = (
    laws_by_year_df
    .join(rules, on="year", how="inner")
    .melt(id_vars=["year"], value_vars=["num_laws_passed", "rule_count"], variable_name="metric", value_name="value")
)

lawrule = lawrule.with_columns(
  pl.col('year').cast(pl.Int32).map_elements(lambda y: f"{y}-01-01")
)

# Prepare Year-over-Year Data for Visualization
df_melted = (
    df_results.melt(
        id_vars=["year"],
        value_vars=["word_growth", "bureaucratic_change", "complexity_change", "efficiency_score"],
        variable_name="metric_type",
        value_name="value"
    )
)

df_melted = df_melted.with_columns(
  pl.col('year').cast(pl.Int32).map_elements(lambda y: f"{y}-01-01")
)

chart1 = (
  charts
  .group_by(['year', 'metric'])
  .agg(pl.col('value').sum().alias('value'))
  .sort(['year', 'metric'])
  .filter(
    pl.col('metric').is_in(['total_word_count', 'DOGE_word_count'])
  )
)

words = (
  charts
  .group_by(["year", "title", "metric"])
  .agg(pl.col("value").sum().alias("value"))
  .sort(["year", "title", "metric"])
  .filter(
    pl.col('metric').is_in(['total_word_count'])
  )
)

chart2 = (
  charts
  .group_by(["year", "title", "metric"])
  .agg(pl.col("value").sum().alias("value"))
  .sort(["year", "title", "metric"])
  .filter(
    pl.col('metric').is_in(['avg_complexity_ratio', 'unconstitutionality_index'])
  )
)

lawrule_pd = lawrule.to_pandas()
chart1_pd = chart1.to_pandas()
word_pd = words.to_pandas()
chart2_pd = chart2.to_pandas()
df_melted_pd = df_melted.to_pandas()

ojs_define(lawrule = lawrule_pd)
ojs_define(chart1 = chart1_pd)
ojs_define(word = word_pd)
ojs_define(chart2 = chart2_pd)
ojs_define(yoy = df_melted_pd)
```

::: {.callout-note title='TL;DR'}
* DOGE is working to create efficiency in savings and regulations
* An open and transparent analysis was conducted alongside the "transparent" DOGE analysis, which did not align
* The DOGE regulatory analysis focuses solely on word count and regulation count without any underlying context like complexity of the issue regulated or the use of langauge within a regulation
* The analysis shows poor understanding of analytics and laziness in providing appropriate context and due dillignece before making extreme and rapid changes that impact millions
* Next time, do better DOGE... and stop making me go to X so your "special governemnt employee" can boost his price per share. To be clear: your analysis isn't worth the $/mo, or the tissue I blew my nose in.
:::

## Background
The Department of Government Efficiency (laughably/ironically/disrespectfully, [DOGE](https://en.wikipedia.org/wiki/Doge_(meme))) was created by [Exeutive Order](https://www.whitehouse.gov/presidential-actions/2025/01/establishing-and-implementing-the-presidents-department-of-government-efficiency/) on Jan. 20 2025. The purpose is defined as:

> "This Executive Order establishes the Department of Government Efficiency to implement the President’s DOGE Agenda, by modernizing Federal technology and software to maximize governmental efficiency and productivity."

Currently, there is ambiguity as to the DOGE administrator as shown in the various sources and quotes in the [Wikipedia article](https://en.wikipedia.org/wiki/Department_of_Government_Efficiency#:~:text=President%20Donald%20Trump%20confirmed%20Elon,required%20of%20full%20time%20employees.):

> "Trump has said that businessman Elon Musk is "in charge" of DOGE, but the White House has denied that Musk is a DOGE administrator or DOGE employee,[9][2][10] and said Musk "has no actual or formal authority to make government decisions"."

The contracted organization-the true status of the organization, not actually a department of the U.S. government-released the first version of their website recently (Feb. 12 2025) attempting to make their effiency findings transparent through monies saved and an assessment of bueraucractic overreach. Many reports of the flaws in their savings analyses have been publicized but a concerning set of analysis is their regulations page which comes into focus with the [latest changes to DOGE's vision](https://www.whitehouse.gov/presidential-actions/2025/02/ensuring-lawful-governance-and-implementing-the-presidents-department-of-government-efficiency-regulatory-initiative/).

Seemingly, the purpose of the page is to look at the amount of regulation (rules from agencies not created by congress) compared to the laws passed by Congress. That is to say there is more government rule making than congressional (representing the people's interests). The main metrics used are word counts by agency and year, and the Unconstitutionality Index.

### Unconstitutionally Index
This index was created by the [Competitive Enterprise Institude](https://cei.org/opeds_articles/the-2025-unconstitutionality-index-exposing-congresss-abdication-of-power/), a nonprofit advocating for "regulatory reform on a wide range of policy issues". While a valid index, it should be treated as such-a tool to measure change in a group of representative data. It can provide a simple metric to track but does not provide full context. 

It is included in this analysis to compare the various metrics being used to asses regulatory reach. The discussion will include why metrics can only represent and should not be removed from context.

Here, these metrics are reviewed and compared to other metrics created for the purpose of this analysis with idea generation and code assistance from generative AI tools (Claude/ChatGPT) which will be flagged where used. All code and data will be available open source for reproducibility and transparency.

## Methods

### Regulations
Regulations are agency-created rules. These are not strictly voted on by the public and are seen by some as bureacuracy or government overreach. A counter point is that elected officials (the President, Congress) nominate and hold hearings to confirm these appointed positions (heads of the agencies) who in turn hire individuals they feel fit the qualifications - not voted on our citizen drawn up rules, but certainly reflective of the elected officials and within the expertise of those that fit the role.

Regulations were pulled from the GovInfo.gov API. All regulations were pulled between 2012 and 2014, looking for titles of regulations, the issued date of the regulation, and a package ID used to identify regulations and their details. Once regulations were pulled, granules (details for each regulation record) were pulled to obtain the agency that produced the regulation and text for each regulation.

These were saved to .csv file stored on Google Drive due to size restrictions on GitHub. The .csv was loaded into python and the following metrics were calculated:
    
  - word count: count of all individual words within the full text of the regulation;
  - bueraucractic terms: count of all terms that described bueraucratic action ("shall", "must", "require", "submit", "authorize", "comply", "prohibit", "enforce", "mandatory"; note this list is not exhaustive but representative);
  - complexity ratio: ratio of bureuacratic terms to explanatory terms ("for the purposes of", "defined as", "background", "explains how"; note this list is not exhaustive but representative)

Percent changes year over year were calculated as:
$$
\text{Percent Change} = \frac{year_{new} - year_{old}}{year_{old}} \times 100
$$

The next calculation was the unconstitutionality index but requires numbers of laws by year. The method for gathering these is defined next.

### Laws
Laws are federal laws that are voted on within the House and Senate. These are seen to be less government overreach and more reflective of the populations desires. To provide a counter point here, the elected officials may speak to their parties by addressing their concerns and promising to uphold those in Congress, but could vote against those concerns or be lobbied in direction that suits the few instad of the many.

Laws were counted from Congress.gov using the search feature for "Laws" between 2012 - 2024. Under "Legislative Action", "Laws Enacted" was selected. The specific congresses were selected by their year span and the years were mapped to congressional sessions. While innaccurate, laws were split evenly by the years of the congressional sessions (divided by 2) for a quick analysis. Improvements would be to manually count for each year that laws were passed but there is currently no automated way of collecting this data.

### Unconstitutionally Index
$$
\text{Unconstitutionality Index} = \frac{n_{regulations}}{{n_{laws}}}
$$

## Results

### Analysis findings
Below is the number of rules and laws by year done with the above method.
```{ojs}
//| label: chart 1
//| echo: false 
//| warning: false 
//| message: false 
Plot = import('https://cdn.jsdelivr.net/npm/@observablehq/plot@0.6.16/+esm')
d3 = require("d3@7")

tlr = transpose(lawrule)

// Ensure date formatting for visualization
tlrFormatted = tlr.map(d => ({...d, year: new Date(d.year, 0, 1)}))

// Grouped column chart (Rules & Laws per year per agency)
Plot.plot({
  marginLeft: 80,
  marginBottom: 40,
  marginRight: 80,
  marginTop: 40,
  width: 960,
  height: 500,
  fx: {label: 'Year', tickFormat: d3.utcFormat("%Y")},
  x: {axis: null, type: 'utc', domain: ['rule_count', 'num_laws_passed']},
  y: {label: 'Count'},
  tip: {
    format: {
      y: d => Intl.NumberFormat().format(d)
    }
  },
  color: {
    legend: true, 
    domain: ['num_laws_passed', 'rule_count'],
    range: ['#345995', '#03CEA4'],
    tickFormat: text => text.replace(/_/g, " ").replace(/^./, str => str.toUpperCase()) 
  },
  marks: [
    Plot.barY(tlrFormatted, {fx: 'year', x: 'metric', y: 'value', fill: 'metric', tip: true,
      title: d => {
        const names = {
          num_laws_passed: 'Laws Passed',
          rule_count: 'Rule Count'
        }
        return `${names[d.metric] || d.metric}: ${d.value.toFixed(2)}`
      }
    }),
    Plot.ruleY([0])
  ]
})
```

There are already discrepancies in the numbers between this analysis and those posted on DOGE. It was difficult to find accurate numbers as there are multiple ways to pull this information and there is not a tidy record of laws by year. DOGE did not provide how they arrived at their numbers, only where the numbers were found. In this analysis, the same source was used but the methods for arriving at the final numbers obviously vary.

In looking at the overall trend, law creation is somewhat stable, while regulations are lower, in total, than they were 12 years ago.

The next chart compares DOGE word counts by year to the above methods word count by year. Due to lack of transparency, it is unclear whether they are using the Code of Federal Regulations (CFR/eCFR) or the Federal Register for calculating words. It is also unclear which area of the regulation that they are counting words.

The method to pull this information quickly and efficiently with some code uses many fields that require a grasp of the definitions for each field and its intended use. For the purpose of this analysis, the "text" field from the eCFR/CFR was used, ignoring anything but the body text of the regulation.
```{ojs}
//| echo: false 
//| warning: false 
//| message: false 
//| label: chart 2
tc1 = transpose(chart1)

// Ensure date formatting for visualization
fc1 = tc1.map(d => ({...d, year: new Date(d.year, 0, 1)}))

// bar chart (word count by agency)
Plot.plot({
  marginLeft: 80,
  marginBottom: 40,
  marginRight: 80,
  marginTop: 40,
  width: 960,
  height: 500,
  fx: {label: 'Year', tickFormat: d3.utcFormat("%Y")},
  x: {axis: null, type: 'utc', label: 'Year', tickFormat: d3.utcFormat("%Y")},
  y: {label: 'Regulatory Metric'},
  tip: {
    format: {
      y: d => Intl.NumberFormat().format(d)
    }
  },
  color: {
    domain: ["total_word_count", "DOGE_word_count"],
    range: ["#EAC435", "#345995"],
    legend: true,
    tickFormat: text => text.replace(/_/g, " ").replace(/^./, str => str.toUpperCase()) 
  },
  marks: [
    Plot.barY(fc1, {fx: 'year', x: 'metric', y: 'value', fill: 'metric', z: 'metric', tip: true,
      title: d => {
        const names = {
          total_word_count: 'Word Count',
          DOGE_word_count: 'DOGE Word Count'
        }
        return `${names[d.metric] || d.metric}: ${d.value.toFixed(2)}`
      }
    }),
    Plot.ruleY([0])
  ]
})
```

It is clear to see that the word counts by DOGE's team are greater than this analysis and calls into question what the methodology was to better understanding the word counts.

But word count alone falls short of a definition of bueruacracy, so the next charts look at various metrics (produced with help from ChatGPT Data Analyst (4o) and Claude Sonnet 3.5) that look at things like bureaucracy, efficiency, and word counts by agency by year, as well as year over year changes. The charts can be filtered by all agencies.

```{ojs}
//| label: chart 3
//| echo: false 
//| warning: false 
//| message: false 
// Grouped line chart (complexity and unconstitutionality index by agency)

tw = transpose(word)
tc2 = tranpose(chart2)


fw = tw.map(d => ({...d, year: new Date(d.year, 0, 1)}))
fc2 = tc2.map(d => ({...d, year: new Date(d.year, 0, 1)}))

// get unique Agencies
uniqueAgencies = [...new Set(fw.map(d => d.title))];
uniqueAgencies.unshift('All')

// Checkbox input for agency selection
viewof agency = Inputs.select(uniqueAgencies, {
    label: "Select Agencies",
    value: ["All"],  // Default to selecting all
    multiple: true
})

filtered = tw.filter(d => 
  agency.includes('All') || agency.includes(d.title)
)          

Plot.plot({
  marginLeft: 80,
  marginBottom: 40,
  marginRight: 80,
  marginTop: 40,
  width: 960,
  height: 500,
  x: {label: 'Year', type: 'utc', tickFormat: d3.utcFormat("%Y")},
  y: {label: 'Word count'},
  color: {
    domain: ["total_word_count"],
    range: ["#EAC435"],
    legend: true,
    tickFormat: text => text.replace(/_/g, " ").replace(/^./, str => str.toUpperCase()) 
  },
  marks: [
    Plot.line(fw, {x: 'year', y: 'value', stroke: 'metric', tip: true,
      title: d => {
        const names = {
          total_word_count: 'Word count'
        }
        return `${names[d.metric] || d.metric}: ${d.value.toFixed(2)}`
      }
    }),
    Plot.ruleY([0])
  ]
})

Plot.plot({
  marginLeft: 80,
  marginBottom: 40,
  marginRight: 80,
  marginTop: 40,
  width: 960,
  height: 500,
  x: {label: 'Year', type: 'utc', tickFormat: d3.utcFormat("%Y")},
  y: {label: 'Regulatory Metric'},
  tip: {
    format: {
      y: d => Intl.NumberFormat().format(d)
    }
  },
  color: {
    domain: ["avg_complexity_ratio", "unconstitutionality_index"],
    range: ["#1C949D", "#FB4D3D"],
    legend: true,
    tickFormat: text => text.replace(/_/g, " ").replace(/^./, str => str.toUpperCase()) 
  },
  marks: [
    Plot.line(fc2, {x: 'year', y: 'value', stroke: 'metric', tip: true,
      title: d => {
        const names = {
          avg_complexity_ratio: 'Complexity Ratio',
          unconstitutionality_index: 'Unconstitutionality Index'
        }
        return `${names[d.metric] || d.metric}: ${d.value.toFixed(2)}`
      }
    }),
    Plot.ruleY([0])
  ]
})
```

The above chart looks specifically at the average complexity ratio which looks to measure regulation complexity. This is defined as:

$$
\text {Complexity Ratio} = \frac{Words_{Bureaucratic}}{{Words_{Explanatory} + 1}}
$$

In the analysis, the text is searched for the following bureuacratic terms (terms that evoke an action):

* shall
* must
* require
* submit
* authorize
* comply
* prohibit
* enforce
* mandatory

Any words that match these in the text are counted and then divided by explanatory terms (terms that explain what is happening):

* "for the purposes of"
* "defined as"
* "background"
* "explains how"

These words do not provide a regulation but add word count with the assumption that they explain and are "less efficient". Obviously, an imperfect metric, but provides more context to how complex regulations can become and how efficient each regulation is with its words as opposed to simple word counts. The one is added to the sum of all matching explanatory words/phrases to ensure there is no division by zero errors. The efficiency ratio is then averaged by year for an agency.

The unconstitutionality index is shown with the complexity ratio for comparison. You can see that regulations are more complex and have more variance, but the "unconsitutionality" looks similar throughout the 12 year span.

```{ojs}
//| label: chart 4
//| echo: false 
//| warning: false 
//| message: false 
tyoy = transpose(yoy)

fyoy = tyoy.map(d => ({...d, year: new Date(d.year, 0, 1)}))

// Grouped line chart (complexity and unconstitutionality index by agency)
Plot.plot({
  marginLeft: 80,
  marginBottom: 40,
  marginRight: 80,
  marginTop: 40,
  width: 960,
  height: 500,
  x: {label: 'Year', type: 'utc',tickFormat: d3.utcFormat("%Y")},
  y: {label: 'Metrics'},
  tip: {
    format: {
      y: d => Intl.NumberFormat().format(d)
    }
  },
  color: {
    scheme: 'dark2',
    legend: true,
    tickFormat: text =>
      typeof text === "string"
        ? text.replace(/_/g, " ").replace(/^./, str => str.toUpperCase())
        : text 
  },
  marks: [
    Plot.line(fyoy, {x: 'year', y: 'value', stroke: 'metric_type', tip: true,
      title: d => {
        const names = {
          word_growth: 'Word Growth',
          bureaucratic_change: 'Bureaucractic Change',
          complexity_change: 'Complexity Change',
          efficiency_score: 'Efficiency Score'
        }
        return `${names[d.metric_type] || d.metric_type}: ${d.value.toFixed(2)}`
      }
    }),
    Plot.ruleY([0])
  ]
})
```

The final chart shows calculations of the year over year change in the number of bureaucratic terms (see above list), the change in complexity (see above definition of complexity ratio, this is the change in the average year over year), the change in word counts, and a calculated efficiency score to find how "efficient" the regulatory text is, defined as:

$$
\text {Efficiency Score} = \frac{\Delta_{bureaucractic} + \Delta_{complexity}}{2 \times \Delta_{words}}
$$

In other words, is the change in bureacracy plus the change in the regulatory complexity more or less than the change in words, or, if there's more words, there needs to be more complexity inside the bureaucratic terms to amke it an "efficient" rule, thereby giving valid reason for the increase in words.

The chart shows that through there is fluctuation depending on the year and administration, but the efficiency score is consistent over the 12 year period.

## Discussion 

### Importance of context
My biggest issue with this analysis by the DOGE team is it does not take any context into account. These agencies are highly specialized in their knowledge and, for most of the worker bees in these agencies, I am willing to bet are not acting maliciously to siphon money from the government (and certainly not in the quantities that say, government contractors might... looking at you McKinsey because others have not been brought to court yet and I believe in due process...).

Another contextual consideration is the amount of complexity changing over time. As huamnity progresses, we discover new technologies, and a select few find new ways to cheat. The agencies are producing regulations to guide and combat these, respectively.

If this is absent from the analysis (which it clearly is when DOGE is only touting humongous numbers without context to blow an issue out of proportion... how am I supposed to know what a good baseline for sections or word counts should be if there is no context to define?), then you are either a very green analyst who needs their work checked, or you are not trying to actually tell an honest story, just a sensationalized story.

A specific example from the above is the number of laws to number of rules comarpison. There are a number of factors that go into both of these counts. For brevity, take the example of laws: they are passed through Congress. If there are delays to sessions or more partisan bickering, fewer laws get passed. Raw numbers alone do not provide an accurate representation. Also, one law can take a lot of time to pass (e.g. the Affordable Care Act is one law. I don't have a word count, but its 906 pages, so we can assume quite a few words.) Sometimes the reason for more words is to be thorough, not bureaucratic. Can there be efficencies? Sure. But that's not where the DOGE regulations page is aiming.

### Importance of transparency
I'll cede, DOGE did post sources... sparingly. I will add that these sources are noted at the bottom with no ties back to the text or charts that are using them; furthermore, if you download the data behind the charts, there is a tidy file that shows years and counts. If you look at the githbu repo for this blog post, you can view the python code that pulls the CFR/eCFR data and you can quickly see that it is not a simple table pulled, nice and tidy, by year and word count.

While they make the bare minimum attempt to be transparent, there is clearly a lack of transparency, just enough to tick a box but not enough for a reproducibility exercise. If you want to be transparent and open to dsicussion about a topic, you include your work and sources. If you want to placate and weave Rumpelstiltskin type thread of golden garbage, you leave everything out.

### Lack of expertise
On the topic of transparency, we don't know all of the lovely individuals working in DOGE. But given the timing of the website release and the [news that was present at the time](https://projects.propublica.org/elon-musk-doge-tracker/), the *software engineers* they hired with, from what I could tell, no real-world data experience, are not capable of producing any quality analysis.

If you are going to do the job, do the job right. Before you can be efficient, you have to understand what's going on in full. That's what an analyst does - collects the data, intergates it, tells the story, and makes recommendations. Speaking as an analyst, this is sloppy, unprofessional, and a bit offensive (and I'm a white Christian heterosexual male so no DEI comments, thanks).

## Conclusion
Ultimately, there probably is work to reduce inefficiencies in regulation but I can confidently say the way that DOGE is conducting it is **not** the way to do it. This is a mess that is aimed to blindside people with large numbers, get them mad at government protocols, and stop questioning DOGE methods. I'm fairly certain the "special government employee" maybe-not-leading-but-authority-figure works off the "first principles" philosophy of approaching a problem which would require better understanding of the first step before gutting it. In short, shape up DOGE. You're being paid far too much and hurtig far too many to being doing such a bad job.

Photo by <a href="https://unsplash.com/@onthesearchforpineapples?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Colin Lloyd</a> on <a href="https://unsplash.com/photos/us-a-flag-on-top-of-black-and-brown-wooden-cabinet-rfeIP9knGJs?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
      